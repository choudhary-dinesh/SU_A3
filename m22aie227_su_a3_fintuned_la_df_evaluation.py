# -*- coding: utf-8 -*-
"""M22AIE227_SU_A3_fintuned_LA_DF_evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/177ScJrjH2g2o2A99jmkr_89Ouwrodpsn

#### Git clone SSL_Anti-spoofing
"""

from google.colab import drive
drive.mount('/content/drive')

!git clone https://github.com/TakHemlata/SSL_Anti-spoofing.git

"""#### Install requirements"""

# !pip install torch==1.8.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html   --not feasible hence installing nearesr version 1.11
!pip install torch==1.11.0

# !pip install torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html  --not feasible hence installing nearesr version 0.12
!pip install torchvision==0.12.0

# !pip install torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html   --not feasible hence installing nearesr version 0.11
!pip install torchaudio==0.11.0

# Commented out IPython magic to ensure Python compatibility.
#installing fairseq
# %cd /content/SSL_Anti-spoofing/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1
!pip install --editable ./

# Commented out IPython magic to ensure Python compatibility.
#installing requirements
# %cd /content/SSL_Anti-spoofing/
!pip install -r requirements.txt

#specific numpy version required for fairseq
!pip install numpy==1.22.4

"""#### Imports"""

import glob
import os
import pandas as pd
import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import Dataset,DataLoader
from torch import Tensor
import librosa

from sklearn.metrics import det_curve,RocCurveDisplay,auc,roc_curve
import matplotlib.pyplot as plt

"""#### Custom Dataset (Dataset_Speech_Assignment)"""

#make new dir & unzip dataset into it
!mkdir /content/Dataset_Speech_Assignment
!unzip '/content/drive/MyDrive/Dataset_Speech_Assignment.zip' -d /content/Dataset_Speech_Assignment/

## provided audio files are from different formst like .wav .mp3 etc, hence converting all files into .flac files
for fil in glob.glob("/content/Dataset_Speech_Assignment/*/*"):
  current_fil = fil
  new_fil = '_'.join(fil.strip().split()).replace('(', '').replace(')', '')
  if '.flac' not in new_fil:
    os.rename(current_fil, new_fil)
    flac_fil = new_fil.split('.')[0] + '.flac'
    !ffmpeg -hide_banner -loglevel error -y -i {new_fil} -ar 16000 {flac_fil}

## creating a dataframe that consists of audio file path, tand their label either real (1) or fake (0)
df = pd.DataFrame(glob.glob("/content/Dataset_Speech_Assignment/*/*.flac"), columns = ['file_path'])
df['real_or_fake'] = df['file_path'].apply(lambda x : x.split('/')[-2])
df['label'] = df['real_or_fake'].apply(lambda x : 1 if x=='Real' else 0)

df.head()

df.tail()

df.label.value_counts()

#utility function that wither truncate or pad audio signal to create a fix lenght signal
def pad(x, max_len=64600//2):
    x_len = x.shape[0]
    if x_len >= max_len:
        return x[:max_len]
    # need to pad
    num_repeats = int(max_len / x_len)+1
    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]
    return padded_x

#custom dataset class for evaluation, this class takes list of audio paths & their labels
class Dataset_eval(Dataset):
  def __init__(self, file_path, label):
    self.file_path = file_path
    self.cut=64600//2 # take ~4//2 sec audio (64600//2 samples) ie 2 secs audio (32300 samples)
    self.label  = label
  def __len__(self):
    return len(self.file_path)
  def __getitem__(self, index):
    X, fs = librosa.load(self.file_path[index], sr=16000)
    X_pad = pad(X,self.cut)
    x_inp = Tensor(X_pad)
    label = self.label[index]
    return x_inp, label

#checking shape of a data point
eval_set = Dataset_eval(df.file_path.tolist(), df.label.tolist())
eval_set[0][0].shape

"""#### Model"""

#downloaded Pre trainned model for LA and saved at  my drive location '/content/drive/MyDrive/LA_model.pth'
#downloaded Pre trainned model XLSR and saved at  my drive location /content/drive/MyDrive/Best_LA_model_for_DF.pth
# above model path need to updated in line 24 in model.py file ie :::  cp_path = '/content/drive/MyDrive/Classroom/xlsr2_300m.pt'

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/SSL_Anti-spoofing

!wget https://dl.fbaipublicfiles.com/fairseq/wav2vec/xlsr2_300m.pt

# updated in line 24 in model.py file ie :::  cp_path = /content/SSL_Anti-spoofing/xlsr2_300m.pt
from model import Model

#define best finetuned model path for LA & DF & output file path for both
args = {
        'finetuned_la_model_path' : '/content/drive/MyDrive/best_finetuned_LA_model.pth',
        'finetuned_df_model_path' : '/content/drive/MyDrive/best_finetuned_DF_model.pth' ,
        'lr' :     0.000001,
        'weight_decay' : 0.0001,
        'la_eval_output' : '/content/finetuned_la_score_custom.txt',
        'df_eval_output' : '/content/finetuned_df_score_custom.txt',
        }

#set device
device = 'cuda' if torch.cuda.is_available() else 'cpu'

def get_model(args, device, la_or_df):
  model = Model(args,device)
  nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])
  model =model.to(device)
  if la_or_df.lower() == 'df':
    model =nn.DataParallel(model).to(device)
    model.load_state_dict(torch.load(args['finetuned_df_model_path'],map_location=device))
    print('Model loaded : {}'.format(args['finetuned_df_model_path']))
  else:
    model.load_state_dict(torch.load(args['finetuned_la_model_path'],map_location=device))
    print('Model loaded : {}'.format(args['finetuned_la_model_path']))
  print('nb_params:',nb_params)
  return model

"""#### Inference (For both LA & DF) on custom dataset"""

def produce_evaluation_file(dataset,batch_size, model, device, save_path):
  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False)
  model.eval()

  for batch_x,label in data_loader:
    label_list = []
    score_list = []
    batch_size = batch_x.size(0)
    batch_x = batch_x.to(device)
    batch_out = model(batch_x)
    batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()
    # add outputs
    label_list.extend(label)
    score_list.extend(batch_score.tolist())
    with open(save_path, 'a+') as fh:
      for l, s in zip(label_list,score_list):
        fh.write('{} {}\n'.format(l, s))
    fh.close()
  print('Scores are saved to {}'.format(save_path))

batch_size = 16
##inference using best finetuned LA model, & saving scores in txt files
model = get_model(args, device, la_or_df='la')
produce_evaluation_file(eval_set,batch_size, model, device, args['la_eval_output'])

batch_size = 16
##inference using best fintuned  DF model, & saving scores in txt files
model = get_model(args, device, la_or_df='df')
produce_evaluation_file(eval_set,batch_size, model, device, args['df_eval_output'])

"""#### Evaluation Metrics (EER & AUC)

"""

#computing EER
def compute_eer(truth, scores):
  frr, far, th = det_curve(truth, scores)
  abs_diffs = np.abs(frr - far)
  min_index = np.argmin(abs_diffs)
  eer = np.mean((frr[min_index], far[min_index]))
  return eer

##plotting ROC Curve with AUC score
def plot_roc_curve_with_auc(truth, scores, la_or_df):
  fpr, tpr, thresholds = roc_curve(truth,scores)
  roc_auc = auc(fpr, tpr)
  display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='example estimator')
  display.plot()
  if la_or_df =='la':
    plt.title("ROC curve with AUC score for finetuned LA model on custom dataset by M22AIE227")
  else:
    plt.title("ROC curve with AUC score for finetunned DF model custom dataset by M22AIE227")
  plt.show()

"""##### LA Model Evaluation"""

la_df = pd.read_csv('/content/finetuned_la_score_custom.txt', sep = ' ', header = None)
la_df.columns = ['truth', 'scores']

la_eer = compute_eer(la_df.truth, la_df.scores)
print("EER (Equal Error Rate) for finetuned LA model custom dataset : ", round(la_eer, 4))

#plotting roc cureve with auc for LA model
plot_roc_curve_with_auc(la_df.truth, la_df.scores, 'la')

"""##### DF Model Evaluation"""

df_df = pd.read_csv('/content/finetuned_df_score_custom.txt', sep = ' ', header = None)
df_df.columns = ['truth', 'scores']

df_eer = compute_eer(df_df.truth, df_df.scores)
print("EER (Equal Error Rate) for fintuned DF model custom dataset : ", round(df_eer, 4))

#plotting roc cureve with auc for LA model
plot_roc_curve_with_auc(df_df.truth, df_df.scores, 'df')

